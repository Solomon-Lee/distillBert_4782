{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets evaluate box"
      ],
      "metadata": {
        "id": "27MsyXvtdCJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWiAqpLRyvzc"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    set_seed,\n",
        ")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOOUPlcgyyrr"
      },
      "outputs": [],
      "source": [
        "seed = random.randrange(2**32)\n",
        "print(f\"üî¢ Using random seed: {seed}\")\n",
        "\n",
        "# Seed all RNGs\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "set_seed(seed)  # also seeds Hugging¬†Face‚Äôs Trainer internals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4MHBw43y67C"
      },
      "outputs": [],
      "source": [
        "glue_tasks = [\n",
        "    \"stsb\"\n",
        "]\n",
        "\n",
        "base_args = {\n",
        "    \"model_name_or_path\":          \"SolomonSLee/TINYdistillBert\",\n",
        "    \"max_seq_length\":              128,\n",
        "    \"per_device_train_batch_size\": 32,\n",
        "    \"per_device_eval_batch_size\":  64,\n",
        "    \"learning_rate\":               2e-5,\n",
        "    \"num_train_epochs\":            3,\n",
        "    \"logging_steps\":               50,\n",
        "    \"weight_decay\":                0.01,\n",
        "    \"save_steps\":                  500,\n",
        "    \"output_dir\":                  \"./glue-results\",  # subfolders per task\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZDy2GyZy8d-",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "all_results = {}\n",
        "best_metrics = {\n",
        "    \"cola\": \"loss\",\n",
        "    \"sst2\": \"accuracy\",\n",
        "    \"mrpc\": \"f1\",\n",
        "    \"qqp\": \"f1\",\n",
        "    \"mnli\": \"accuracy\",\n",
        "    \"qnli\": \"accuracy\",\n",
        "    \"rte\": \"accuracy\",\n",
        "    \"wnli\": \"accuracy\",\n",
        "    \"stsb\": \"pearson\",\n",
        "}\n",
        "\n",
        "model_variants = {\n",
        "    \"TinyDistilBERT\":       \"SolomonSLee/TINYdistillBert\",\n",
        "    \"DistilBERT-base\":      \"distilbert-base-uncased\",\n",
        "    \"BERT-base\":            \"bert-base-uncased\",\n",
        "}\n",
        "\n",
        "\n",
        "for model_name, model_path in model_variants.items():\n",
        "    print(f\"\\n===== MODEL: {model_name} ({model_path}) =====\")\n",
        "    # update the base_args for this model\n",
        "    base_args[\"model_name_or_path\"] = model_path\n",
        "\n",
        "    # storage for this model‚Äôs tasks\n",
        "    all_results[model_name] = {}\n",
        "\n",
        "    for task in glue_tasks:\n",
        "        print(f\"\\n===== TASK: {task.upper()} =====\")\n",
        "        args = base_args.copy()\n",
        "        args[\"task_name\"]  = task\n",
        "        args[\"output_dir\"] = f\"{base_args['output_dir']}/{model_name}/{task}\"\n",
        "\n",
        "        # 1) Load data & metric\n",
        "        ds     = load_dataset(\"glue\", args[\"task_name\"])\n",
        "        metric = evaluate.load(\"glue\", args[\"task_name\"])\n",
        "\n",
        "        # 2) Tokenizer & collator\n",
        "        tokenizer     = AutoTokenizer.from_pretrained(args[\"model_name_or_path\"])\n",
        "        data_collator = DataCollatorWithPadding(tokenizer)\n",
        "\n",
        "        # 3) Preprocess\n",
        "        def preprocess_fn(ex):\n",
        "          # Single‚Äêsentence tasks\n",
        "          if task in (\"sst2\", \"cola\"):\n",
        "              return tokenizer(\n",
        "                  ex[\"sentence\"],\n",
        "                  truncation=True,\n",
        "                  padding=\"max_length\",\n",
        "                  max_length=args[\"max_seq_length\"]\n",
        "              )\n",
        "\n",
        "          # STS‚ÄëB: sentence pair regression\n",
        "          if task == \"stsb\":\n",
        "              return tokenizer(\n",
        "                  ex[\"sentence1\"], ex[\"sentence2\"],\n",
        "                  truncation=True,\n",
        "                  padding=\"max_length\",\n",
        "                  max_length=args[\"max_seq_length\"]\n",
        "              )\n",
        "\n",
        "          # MNLI: \"premise\" + \"hypothesis\"\n",
        "          if task == \"mnli\":\n",
        "              return tokenizer(\n",
        "                  ex[\"premise\"], ex[\"hypothesis\"],\n",
        "                  truncation=True,\n",
        "                  padding=\"max_length\",\n",
        "                  max_length=args[\"max_seq_length\"]\n",
        "              )\n",
        "\n",
        "          # QNLI: \"question\" + \"sentence\"\n",
        "          if task == \"qnli\":\n",
        "              return tokenizer(\n",
        "                  ex[\"question\"], ex[\"sentence\"],\n",
        "                  truncation=True,\n",
        "                  padding=\"max_length\",\n",
        "                  max_length=args[\"max_seq_length\"]\n",
        "              )\n",
        "\n",
        "          # MRPC: \"sentence1\" + \"sentence2\"\n",
        "          if task == \"mrpc\":\n",
        "              return tokenizer(\n",
        "                  ex[\"sentence1\"], ex[\"sentence2\"],\n",
        "                  truncation=True,\n",
        "                  padding=\"max_length\",\n",
        "                  max_length=args[\"max_seq_length\"]\n",
        "              )\n",
        "\n",
        "          # QQP: \"question1\" + \"question2\"\n",
        "          if task == \"qqp\":\n",
        "              return tokenizer(\n",
        "                  ex[\"question1\"], ex[\"question2\"],\n",
        "                  truncation=True,\n",
        "                  padding=\"max_length\",\n",
        "                  max_length=args[\"max_seq_length\"]\n",
        "              )\n",
        "\n",
        "          # RTE & WNLI: also \"sentence1\" + \"sentence2\"\n",
        "          if task in (\"rte\", \"wnli\"):\n",
        "              return tokenizer(\n",
        "                  ex[\"sentence1\"], ex[\"sentence2\"],\n",
        "                  truncation=True,\n",
        "                  padding=\"max_length\",\n",
        "                  max_length=args[\"max_seq_length\"]\n",
        "              )\n",
        "\n",
        "          # Fallback (shouldn't hit if all tasks are covered)\n",
        "          raise ValueError(f\"Unrecognized GLUE task: {task}\")\n",
        "\n",
        "\n",
        "        encoded = ds.map(preprocess_fn, batched=True)\n",
        "\n",
        "        # 4) Model\n",
        "        num_labels = 1 if args[\"task_name\"] == \"stsb\" else ds[\"train\"].features[\"label\"].num_classes\n",
        "        model      = AutoModelForSequenceClassification.from_pretrained(\n",
        "                        args[\"model_name_or_path\"],\n",
        "                        num_labels=num_labels\n",
        "                    )\n",
        "\n",
        "        # 5) TrainingArguments\n",
        "        metric_name = best_metrics[task]\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=args[\"output_dir\"],\n",
        "            seed=seed,\n",
        "            per_device_train_batch_size=args[\"per_device_train_batch_size\"],\n",
        "            per_device_eval_batch_size=args[\"per_device_eval_batch_size\"],\n",
        "            learning_rate=args[\"learning_rate\"],\n",
        "            num_train_epochs=args[\"num_train_epochs\"],\n",
        "            logging_steps=args[\"logging_steps\"],\n",
        "            save_steps=args[\"save_steps\"],\n",
        "            eval_strategy=\"epoch\",\n",
        "            save_strategy=\"epoch\",\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model = metric_name,\n",
        "            overwrite_output_dir=True,\n",
        "        )\n",
        "\n",
        "        # 6) Metrics function\n",
        "        def compute_metrics(p):\n",
        "            logits, labels = p\n",
        "            if task == \"stsb\":\n",
        "                preds = np.squeeze(logits)\n",
        "            else:\n",
        "                preds = np.argmax(logits, axis=-1)\n",
        "            return metric.compute(predictions=preds, references=labels)\n",
        "\n",
        "        # 7) Trainer setup\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=encoded[\"train\"],\n",
        "            eval_dataset=(\n",
        "                encoded[\"validation_matched\"] if task == \"mnli\"\n",
        "                else encoded[\"validation\"]\n",
        "            ),\n",
        "            tokenizer=tokenizer,\n",
        "            data_collator=data_collator,\n",
        "            compute_metrics=compute_metrics\n",
        "        )\n",
        "\n",
        "        # 8) Train & evaluate\n",
        "        trainer.train()\n",
        "        result = trainer.evaluate()\n",
        "        all_results[task] = result\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Define a dict of \"display name\" -> model identifier or path\n",
        "model_variants = {\n",
        "    \"TinyDistilBERT (fine-tuned)\": f\"{base_args['output_dir']}/TinyDistilBERT/stsb/checkpoint-540\",\n",
        "    \"BERT-base-uncased (fine-tuned)\":          f\"{base_args['output_dir']}/BERT-base/stsb/checkpoint-540\",\n",
        "    \"DistilBERT-base (fine-tuned)\":                f\"{base_args['output_dir']}/DistilBERT-base/stsb/checkpoint-540\",\n",
        "}\n",
        "\n",
        "torch.set_num_threads(1)\n",
        "\n",
        "# 2) For each model: load tokenizer + model, build a DataLoader, warm up & time\n",
        "for name, model_id in model_variants.items():\n",
        "    print(f\"\\n=== Timing {name} ===\")\n",
        "\n",
        "    # ---- load tokenizer & model ----\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "    model     = AutoModelForSequenceClassification.from_pretrained(\n",
        "                    model_id,\n",
        "                    num_labels=1\n",
        "                ).to(\"cpu\").eval()\n",
        "\n",
        "    # ---- prepare the dataset ----\n",
        "    # (re-tokenize with the model‚Äôs vocab so we get the right padding & IDs)\n",
        "    raw_val = load_dataset(\"glue\", \"stsb\")[\"validation\"]\n",
        "    def tok_fn(ex):\n",
        "        return tokenizer(\n",
        "            ex[\"sentence1\"], ex[\"sentence2\"],\n",
        "            truncation=True, padding=\"max_length\", max_length=128\n",
        "        )\n",
        "    encoded = raw_val.map(tok_fn, batched=True)\n",
        "\n",
        "    # drop text columns, keep only model inputs as torch tensors\n",
        "    cols = tokenizer.model_input_names\n",
        "    val_ds = encoded.remove_columns(\n",
        "        [c for c in encoded.column_names if c not in cols]\n",
        "    )\n",
        "    val_ds.set_format(type=\"torch\", columns=cols)\n",
        "\n",
        "    loader = DataLoader(val_ds, batch_size=1, shuffle=False)\n",
        "\n",
        "    # ---- warm-up (10 examples) ----\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(loader):\n",
        "            _ = model(**batch)\n",
        "            if i >= 10:\n",
        "                break\n",
        "\n",
        "    # ---- timed inference ----\n",
        "    start = time.perf_counter()\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            _ = model(**batch)\n",
        "    end = time.perf_counter()\n",
        "\n",
        "    total = end - start\n",
        "    per_ex = total / len(loader)\n",
        "    print(f\"Full-pass time: {total:.2f} s\")\n",
        "    print(f\"Average / example: {per_ex:.4f} s\")"
      ],
      "metadata": {
        "id": "Xj3ImsWAuoym"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}